{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRqT8uayl0AH"
      },
      "outputs": [],
      "source": [
        "##Import required libraries and packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sb\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import torchvision.transforms as Tranforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torch.nn as nn\n",
        "import matplotlib.gridspec as gridspec\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "torch.set_default_device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltju9Ystmmnv",
        "outputId": "0cdf844b-19c6-4a29-d160-4b8f2405e981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "##Mount Google Drive to store tensors\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxSTPf8pgzYU",
        "outputId": "4ec6e04f-6313-48a2-976d-7f399f0e9940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        "  torch.set_default_device(\"cuda\")\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  torch.set_default_device(\"cpu\")\n",
        "  device = 'cpu'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV8rC_8NGoIC",
        "outputId": "15e134d0-661e-41d0-9ab4-072006f3f9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12223906.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "CIFAR: torch.Size([1, 3072])\n",
            "CIFAR: (50000, 32, 32, 3)\n",
            "Files already downloaded and verified\n",
            "CIFAR: torch.Size([1, 3072])\n",
            "CIFAR: (10000, 32, 32, 3)\n",
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [02:46<00:00, 15836154.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./stl10_binary.tar.gz to ./\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STL10: torch.Size([1, 3072])\n",
            "STL10: (5000, 3, 96, 96)\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:15<00:00, 11802797.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVHN: torch.Size([1, 3072])\n",
            "SVHN: (73257, 3, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as data\n",
        "import torchvision.transforms as Transforms\n",
        "\n",
        "Tflatten = Transforms.Lambda(lambda x: torch.flatten(x))\n",
        "Tcuda = Transforms.Lambda(lambda x: x.to(\"cuda\"))\n",
        "Tfloat = Transforms.Lambda(lambda x: x.to(torch.float))\n",
        "\n",
        "T = Transforms.Compose([Transforms.ToTensor(), Tfloat, Tflatten, Tcuda])\n",
        "cifar_train = data.CIFAR10(\"./\", train = True, download = True, transform=T)\n",
        "cifar_dataloader = torch.utils.data.DataLoader(cifar_train)\n",
        "print(\"CIFAR:\", next(iter(cifar_dataloader))[0].shape)\n",
        "print(\"CIFAR:\", cifar_train.data.shape)\n",
        "\n",
        "T = Transforms.Compose([Transforms.ToTensor(), Tfloat, Transforms.Normalize(mean = [0,0,0], std = [5,5,5]), Tflatten, Tcuda])\n",
        "cifar_test = data.CIFAR10(\"./\", train = False, download = True, transform=T)\n",
        "cifar_dataloader = torch.utils.data.DataLoader(cifar_test)\n",
        "print(\"CIFAR:\", next(iter(cifar_dataloader))[0].shape)\n",
        "print(\"CIFAR:\", cifar_test.data.shape)\n",
        "\n",
        "T = Transforms.Compose([Transforms.ToTensor(), Transforms.Resize((32,32)), Tfloat, Transforms.Normalize(mean = [0,0,0], std = [5,5,5]), Tflatten, Tcuda])\n",
        "stl10_train = data.STL10(\"./\", split = 'train', download = True, transform=T)\n",
        "stl10_dataloader = torch.utils.data.DataLoader(stl10_train)\n",
        "print(\"STL10:\", next(iter(stl10_dataloader))[0].shape)\n",
        "print(\"STL10:\", stl10_train.data.shape)\n",
        "\n",
        "\n",
        "T = Transforms.Compose([Transforms.ToTensor(), Tfloat, Transforms.Normalize(mean = [0,0,0], std = [5,5,5]), Tflatten, Tcuda])\n",
        "svhn_train = data.SVHN(\"./\", split = 'train', download = True, transform=T)\n",
        "svhn_dataloader = torch.utils.data.DataLoader(svhn_train)\n",
        "print(\"SVHN:\", next(iter(svhn_dataloader))[0].shape)\n",
        "print(\"SVHN:\", svhn_train.data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JON3kLecZc0F",
        "outputId": "4d8ca74a-4fb1-49a6-889a-0c70d40abceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "STL10: torch.Size([1, 3072])\n",
            "STL10: (8000, 3, 96, 96)\n"
          ]
        }
      ],
      "source": [
        "T = Transforms.Compose([Transforms.ToTensor(), Transforms.Resize((32,32)), Tfloat, Transforms.Normalize(mean = [0,0,0], std = [5,5,5]), Tflatten, Tcuda])\n",
        "stl10_test = data.STL10(\"./\", split = 'test', download = True, transform=T)\n",
        "stl10_dataloader = torch.utils.data.DataLoader(stl10_test)\n",
        "print(\"STL10:\", next(iter(stl10_dataloader))[0].shape)\n",
        "print(\"STL10:\", stl10_test.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsUrJmVXGo2z"
      },
      "outputs": [],
      "source": [
        "def eigen_squared(cr, z):\n",
        "  num = z * cr ** 2 + cr ** 2 + z * cr - 2*cr + 1\n",
        "  den = 2*z**2*cr * np.sqrt(4*z*cr**2 + (1-cr + cr*z)**2)\n",
        "  return num/den + (1-1/cr)/(2*z**2)\n",
        "\n",
        "def scale(cr,z):\n",
        "  return 0.5 + (1+z*cr-np.sqrt(4*z*cr**2 + (1-cr + cr*z)**2))/(2*cr)\n",
        "\n",
        "def scale_squared(cr,z):\n",
        "  return -0.5 + (1+cr+z*cr)/(2*np.sqrt(4*z*cr**2 + (1-cr + cr*z)**2))\n",
        "\n",
        "def scale_both_squared(cr,z):\n",
        "  return scale(cr,z) - z*scale_squared(cr,z)\n",
        "\n",
        "def var(c,r,d,N):\n",
        "  cr = r/N\n",
        "  if c < 1:\n",
        "    return r * (scale_both_squared(cr, 1/c) + scale_squared(cr,1/c))/(d*(1-c))\n",
        "  else:\n",
        "    return r * c * scale(cr,1) / (d*(c-1))\n",
        "\n",
        "def calc_gen_error_new(M,ntrn,c,ntst,r,S1,L):\n",
        "  gen_error = 0\n",
        "  if c<1:\n",
        "    gen_error += (torch.diag(1/(1+S1**2*c)) @ L).square().sum()/L.shape[1]\n",
        "  if c>1:\n",
        "    gen_error += (torch.diag(1/(1+S1**2)) @ L).square().sum()/L.shape[1]\n",
        "\n",
        "  return gen_error + var(c,r,M,ntrn)\n",
        "\n",
        "# Cov might need to be diagonal....\n",
        "def calc_gen_error_new_new(M,ntrn,c,ntst,r,S1,Cov):\n",
        "  gen_error = 0\n",
        "  if c<1:\n",
        "    gen_error += eigen_squared(r/ntrn, 1/c) * (Cov).square().sum()/(c**2)\n",
        "  if c>1:\n",
        "    gen_error += eigen_squared(r/ntrn, 1) * (Cov).square().sum()\n",
        "\n",
        "  return gen_error + var(c,r,M,ntrn)\n",
        "\n",
        "def calc_gen_error(M,ntrn,c,ntst,r,S1,L):\n",
        "  gen_error = 0\n",
        "  if c<1:\n",
        "    gen_error += (torch.diag(1/(1+S1**2*c)) @ L).square().sum()/L.shape[1]\n",
        "  if c>1:\n",
        "    gen_error += (torch.diag(1/(1+S1**2)) @ L).square().sum()/L.shape[1]\n",
        "  \n",
        "  gen_error += calc_wnorm(c,r,S1)/M\n",
        "\n",
        "  return gen_error \n",
        "\n",
        "def calc_gen_error_regression(M,ntrn,c,ntst,r,S1,L,betahat):\n",
        "  gen_error = 0\n",
        "  if c<1:\n",
        "    gen_error += (betahat.T @ torch.diag(1/(1+S1**2*c)) @ L).square().sum()/L.shape[1]\n",
        "  if c>1:\n",
        "    gen_error += (betahat.T @ torch.diag(1/(1+S1**2)) @ L).square().sum()/L.shape[1]\n",
        "  \n",
        "  gen_error += calc_wnorm_regression(c,r,S1,betahat)/M\n",
        "\n",
        "  return gen_error \n",
        "\n",
        "def calc_lower_bound(M,ntrn,c,ntst,r,S1,L,alpha):\n",
        "  wnorm_root = calc_wnorm(c,r,S1).sqrt()\n",
        "  if c<1:\n",
        "    bias = (torch.diag(1/(1+S1**2*c)) @ L).square().sum().sqrt()\n",
        "  if c>1:\n",
        "    bias = (torch.diag(1/(1+S1**2)) @ L).square().sum().sqrt()\n",
        "  \n",
        "  bias = (bias-alpha*(wnorm_root+1))**2/L.shape[0]\n",
        "\n",
        "  return bias + wnorm_root.square()/M\n",
        "\n",
        "def calc_upper_bound(M,ntrn,c,ntst,r,S1,L,alpha):\n",
        "  wnorm_root = calc_wnorm(c,r,S1).sqrt()\n",
        "  if c<1:\n",
        "    bias = (torch.diag(1/(1+S1**2*c)) @ L).square().sum().sqrt()\n",
        "  if c>1:\n",
        "    bias = (torch.diag(1/(1+S1**2)) @  L).square().sum().sqrt()\n",
        "  \n",
        "  bias = (bias+alpha*(wnorm_root+1))**2/L.shape[0]\n",
        "\n",
        "  return bias + wnorm_root.square()/M\n",
        "\n",
        "def calc_W_minus_I_norm(c,r,S1,M):\n",
        "  wnorm = 0\n",
        "  if c<1:\n",
        "    for i in range(1):\n",
        "      wnorm = wnorm +  (((c**2*(S1[i]**2 + S1[i]**4))/((1+S1[i]**2*c)**2*(1-c))).sqrt()+1)**2\n",
        "  if c>1:\n",
        "    for i in range(1):\n",
        "      wnorm = wnorm +  (((c*S1[i]**2)/((1+S1[i]**2)*(c-1))).sqrt()+1).square()\n",
        "  return wnorm\n",
        "\n",
        "def calc_wnorm(c,r,S1):\n",
        "  wnorm = 0\n",
        "  if c<1:\n",
        "    for i in range(r):\n",
        "      wnorm = wnorm +  ((S1[i]**2 + S1[i]**4))/((1/c+S1[i]**2)**2*(1-c))\n",
        "  if c>1:\n",
        "    for i in range(r):\n",
        "      wnorm = wnorm +  (c*S1[i]**2)/((1+S1[i]**2)*(c-1))\n",
        "\n",
        "  return wnorm \n",
        "\n",
        "def calc_wnorm_regression(c,r,S1,betahat):\n",
        "  wnorm = 0\n",
        "  if c<1:\n",
        "    for i in range(r):\n",
        "      wnorm = wnorm +  betahat[i,0]**2 * (c**2*(S1[i]**2 + S1[i]**4))/((1+S1[i]**2*c)**2*(1-c))\n",
        "  if c>1:\n",
        "    for i in range(r):\n",
        "      wnorm = wnorm +  betahat[i,0]**2 * (c*S1[i]**2)/((1+S1[i]**2)*(c-1))\n",
        "\n",
        "  return wnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCZ8EvSwcEOZ"
      },
      "outputs": [],
      "source": [
        "path1_rank = F\"/content/drive/MyDrive/Denoising/dataRanks/\"\n",
        "path2_rank = F\"/content/drive/MyDrive/Denoising/dataRanks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr5G77loIOrv",
        "outputId": "4e2bea7e-4fb9-4c02-9d5a-16d1ae5ac277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "torch.Size([3072, 1050]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n",
            "torch.Size([3072, 10400]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n",
            "100\n",
            "torch.Size([3072, 1050]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n",
            "torch.Size([3072, 10400]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "##store more r values for pcr in subspace, out of subspace for small alpha, linear regression, iid test \n",
        "\n",
        "from numpy.lib.arraysetops import setxor1d\n",
        "## Low SNR error \n",
        "\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int)\n",
        "#N = torch.arange(7100,10500,550).to(torch.int)\n",
        "#r_values = [1,2,3,5,10,20,50,100,150,200,250]\n",
        "# r_values = [50]\n",
        "r_values = [50,100]\n",
        "\n",
        "#r_values = [100]\n",
        "# N = torch.arange(500,1000,500)\n",
        "# r_values = [1,100]\n",
        "Ntst = 2500\n",
        "\n",
        "##pcr in subspace\n",
        "Err_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "##pcr out of subspace at alpha = 0.1 \n",
        "\n",
        "\n",
        "alpha_cifar = 0.1*torch.ones(len(r_values),N.shape[0]).to(device)\n",
        "alpha_stl10 = 0.1*torch.ones(len(r_values),N.shape[0]).to(device)\n",
        "alpha_svhn = 0.1*torch.ones(len(r_values),N.shape[0]).to(device)\n",
        "\n",
        "Err_stl10_bound = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_stl10_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_svhn_bound = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar_bound = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_cifar_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar_alpha = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "##pcr out of subspace (outss)\n",
        "Err_stl10_bound_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical bound\n",
        "Err_stl10_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_svhn_bound_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar_bound_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_cifar_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar_outss = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "\n",
        "##iid-test data \n",
        "\n",
        "\n",
        "Err_iid_test = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_iid_test = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "##linear regression\n",
        "Err_stl10_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar_reg = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "beta = torch.randn(M,1)\n",
        "beta /= torch.norm(beta)\n",
        "\n",
        "T = 200 #Number of runs\n",
        "\n",
        "for i,r in list(enumerate(r_values)):\n",
        "  print(r)\n",
        "  for j in range(N.shape[0]):\n",
        "    c = M/N[j]\n",
        "    cifar_train_data = torch.utils.data.DataLoader(cifar_train, batch_size = N[j].item(), shuffle = False)\n",
        "    Xtrn = next(iter(cifar_train_data))[0].T\n",
        "\n",
        "    cifar_test_data = torch.utils.data.DataLoader(cifar_test, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_cifar = next(iter(cifar_test_data))[0].T\n",
        "\n",
        "    stl10_data = torch.utils.data.DataLoader(stl10_train, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_stl10 = next(iter(stl10_data))[0].T\n",
        "\n",
        "    svhn_data = torch.utils.data.DataLoader(svhn_train, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_svhn = next(iter(svhn_data))[0].T\n",
        "\n",
        "    print(Xtrn.shape, Xtst_cifar.shape)\n",
        "\n",
        "    print(c)\n",
        "    U,S,Vh = torch.linalg.svd(Xtrn)\n",
        "    Xtrn = U[:,:r] @ torch.diag(S[:r]) @ Vh[:r,:]\n",
        "\n",
        "    P = U[:,:r] @ U[:,:r].T\n",
        "\n",
        "    Xtst_cifar_proj = P @ Xtst_cifar\n",
        "    Xtst_stl10_proj = P @ Xtst_stl10\n",
        "    Xtst_svhn_proj = P @ Xtst_svhn\n",
        "\n",
        "    L_cifar = U[:,:r].T @ Xtst_cifar\n",
        "    L_stl10 = U[:,:r].T @ Xtst_stl10\n",
        "    L_svhn = U[:,:r].T @ Xtst_svhn\n",
        "\n",
        "    ##pcr in subspace \n",
        "    # Err_cifar[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_cifar)\n",
        "    # Err_stl10[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_stl10)\n",
        "    # Err_svhn[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_svhn)\n",
        "\n",
        "    ##pcr out of subspace for alpha = 0.1\n",
        "    # Xtst_cifar_alpha = Xtst_cifar_proj + 0.1*torch.randn_like(Xtst_cifar)/np.sqrt(M*Ntst)\n",
        "    # Xtst_stl10_alpha = Xtst_stl10_proj + 0.1*torch.randn_like(Xtst_stl10)/np.sqrt(M*Ntst)\n",
        "    # Xtst_svhn_alpha = Xtst_svhn_proj + 0.1*torch.randn_like(Xtst_svhn)/np.sqrt(M*Ntst)\n",
        "\n",
        "    # Err_cifar_bound[i,j] = alpha_cifar[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "    # Err_stl10_bound[i,j] = alpha_stl10[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "    # Err_svhn_bound[i,j] = alpha_svhn[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "\n",
        "    # Err_cifar_alpha[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_cifar)\n",
        "    # Err_stl10_alpha[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_stl10)\n",
        "    # Err_svhn_alpha[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_svhn)\n",
        "\n",
        "    ## pcr out of subspace for large alpha\n",
        "    alpha_cifar[i,j] = (Xtst_cifar_proj - Xtst_cifar).square().sum().sqrt()\n",
        "    alpha_stl10[i,j] = (Xtst_stl10_proj - Xtst_stl10).square().sum().sqrt()\n",
        "    alpha_svhn[i,j] = (Xtst_svhn_proj - Xtst_svhn).square().sum().sqrt()\n",
        "\n",
        "    # Err_cifar_bound_outss[i,j] = alpha_cifar[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "    # Err_stl10_bound_outss[i,j] = alpha_stl10[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "    # Err_svhn_bound_outss[i,j] = alpha_svhn[i,j]**2 * calc_W_minus_I_norm(c,r,S[:r],M)/Ntst\n",
        "\n",
        "    # Err_cifar_outss[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_cifar)\n",
        "    # Err_stl10_outss[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_stl10)\n",
        "    # Err_svhn_outss[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_svhn)\n",
        "\n",
        "\n",
        "    # ##iid test data\n",
        "    # Cov_root = torch.randn(r,r)/np.sqrt(r)\n",
        "\n",
        "    # L = Cov_root @ torch.randn(r,Ntst)/np.sqrt(r)\n",
        "    # Ul, Sl, _ = torch.linalg.svd(L)\n",
        "\n",
        "    # Xtst = U[:,:r] @ L\n",
        "\n",
        "    # Err_iid_test[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],Cov_root @ torch.eye(r)*np.sqrt(Ntst/r))\n",
        "\n",
        "    # ##linear regression \n",
        "    # betahat = (beta.T @ U[:,:r]).T\n",
        "\n",
        "    # Err_cifar_reg[i,j] = calc_gen_error_regression(M,N[j],c,Ntst,r,S[:r],L_cifar, betahat)\n",
        "    # Err_stl10_reg[i,j] = calc_gen_error_regression(M,N[j],c,Ntst,r,S[:r],L_stl10, betahat)\n",
        "    # Err_svhn_reg[i,j] = calc_gen_error_regression(M,N[j],c,Ntst,r,S[:r],L_svhn, betahat)\n",
        "\n",
        "    # for k in tqdm(range(T)):\n",
        "    #     Atrn = torch.randn_like(Xtrn)/np.sqrt(M)\n",
        "    #     W = Xtrn.mm(torch.pinverse(Xtrn+Atrn))\n",
        "\n",
        "    #     ## PCR in subspace \n",
        "\n",
        "    #     Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "    #     Err_emp_cifar[i,j] += (Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "    #     Err_emp_stl10[i,j] += (Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "    #     Err_emp_svhn[i,j] += (Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     ##pcr out of subspace at alpha = 0.1 \n",
        "    #     Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_cifar_alpha + Atst_cifar)\n",
        "    #     Err_emp_cifar_alpha[i,j] += (Xtst_cifar_alpha - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_stl10_alpha + Atst_stl10)\n",
        "    #     Err_emp_stl10_alpha[i,j] += (Xtst_stl10_alpha - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_svhn_alpha + Atst_svhn)\n",
        "    #     Err_emp_svhn_alpha[i,j] += (Xtst_svhn_alpha - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     ##pcr out of subspace for large alpha\n",
        "    #     Atst_cifar = torch.randn_like(Xtst_cifar)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_cifar + Atst_cifar)\n",
        "    #     Err_emp_cifar_outss[i,j] += (Xtst_cifar - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_stl10 + Atst_stl10)\n",
        "    #     Err_emp_stl10_outss[i,j] += (Xtst_stl10 - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_svhn + Atst_svhn)\n",
        "    #     Err_emp_svhn_outss[i,j] += (Xtst_svhn - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     ##iid test data\n",
        "    #     Atst = torch.randn_like(Xtst)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst + Atst)\n",
        "    #     Err_emp_iid_test[i,j] += (Xtst - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     ##linear regression\n",
        "    #     W = beta.T @ W\n",
        "    #     Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "    #     Err_emp_cifar_reg[i,j] += (beta.T @ Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "    #     Err_emp_stl10_reg[i,j] += (beta.T @ Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    #     Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "    #     Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "    #     Err_emp_svhn_reg[i,j] += (beta.T @ Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "    # # print(wnorm, bias)\n",
        "    # # print(emp_norm, emp_bias)\n",
        "    \n",
        "    # # print((Err_emp_cifar[i,j]-Err_cifar[i,j]).abs()/Err_emp_cifar[i,j])\n",
        "    # # print((Err_emp_stl10[i,j]-Err_stl10[i,j]).abs()/Err_emp_stl10[i,j])\n",
        "    # # print((Err_emp_svhn[i,j]-Err_svhn[i,j]).abs()/Err_emp_svhn[i,j])\n",
        "\n",
        "    # # torch.save(Err_emp_cifar,path2_rank+\"cifar-emp-ranks.pt\")\n",
        "    # # torch.save(Err_cifar,path1_rank+\"cifar-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_stl10,path2_rank+\"stl10-emp-ranks.pt\")\n",
        "    # # torch.save(Err_stl10,path1_rank+\"stl10-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_svhn,path2_rank+\"svhn-emp-ranks.pt\")\n",
        "    # # torch.save(Err_svhn,path1_rank+\"svhn-ranks.pt\")    \n",
        "\n",
        "    # # torch.save(Err_emp_cifar_alpha,path2_rank+\"cifar-emp-alpha-ranks.pt\")\n",
        "    # # torch.save(Err_cifar_alpha,path1_rank+\"cifar-alpha-ranks.pt\")  \n",
        "    # # torch.save(Err_cifar_bound,path1_rank+\"cifar-bound-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_stl10_alpha,path2_rank+\"stl10-emp-alpha-ranks.pt\")\n",
        "    # # torch.save(Err_stl10_alpha,path1_rank+\"stl10-alpha-ranks.pt\")  \n",
        "    # # torch.save(Err_stl10_bound,path1_rank+\"stl10-bound-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_svhn_alpha,path2_rank+\"svhn-emp-alpha-ranks.pt\")\n",
        "    # # torch.save(Err_svhn_alpha,path1_rank+\"svhn-alpha-ranks.pt\")  \n",
        "    # # torch.save(Err_svhn_bound,path1_rank+\"svhn-bound-ranks.pt\")   \n",
        "\n",
        "    # # torch.save(Err_emp_cifar_outss,path2_rank+\"cifar-emp-outss-ranks.pt\")\n",
        "    # # torch.save(Err_cifar_outss,path1_rank+\"cifar-outss-ranks.pt\")  \n",
        "    # # torch.save(Err_cifar_bound_outss,path1_rank+\"cifar-bound-outss-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_stl10_outss,path2_rank+\"stl10-emp-outss-ranks.pt\")\n",
        "    # # torch.save(Err_stl10_outss,path1_rank+\"stl10-outss-ranks.pt\")  \n",
        "    # # torch.save(Err_stl10_bound_outss,path1_rank+\"stl10-bound-outss-ranks.pt\")  \n",
        "    # # torch.save(Err_emp_svhn_outss,path2_rank+\"svhn-emp-outss-ranks.pt\")\n",
        "    # # torch.save(Err_svhn_outss,path1_rank+\"svhn-outss-ranks.pt\")  \n",
        "    # # torch.save(Err_svhn_bound_outss,path1_rank+\"svhn-bound-outss-ranks.pt\") \n",
        "\n",
        "    # # torch.save(Err_emp_iid_test,path2_rank+\"emp-iid-test-ranks.pt\")\n",
        "    # # torch.save(Err_iid_test,path1_rank+\"iid-test-ranks.pt\")\n",
        "    \n",
        "    # # torch.save(Err_emp_cifar_reg,path2_rank+\"cifar-emp-reg-ranks.pt\")\n",
        "    # # torch.save(Err_cifar_reg,path1_rank+\"cifar-reg-ranks.pt\")\n",
        "    # # torch.save(Err_emp_stl10_reg,path2_rank+\"stl10-emp-reg-ranks.pt\")\n",
        "    # # torch.save(Err_stl10_reg,path1_rank+\"stl10-reg-ranks.pt\")\n",
        "    # # torch.save(Err_emp_svhn_reg,path2_rank+\"svhn-emp-reg-ranks.pt\")\n",
        "    # # torch.save(Err_svhn_reg,path1_rank+\"svhn-reg-ranks.pt\")\n",
        "\n",
        "    # torch.save(Err_emp_cifar,path2_rank+\"cifar-emp-rank100.pt\")\n",
        "    # torch.save(Err_cifar,path1_rank+\"cifar-rank100.pt\")  \n",
        "    # torch.save(Err_emp_stl10,path2_rank+\"stl10-emp-rank100.pt\")\n",
        "    # torch.save(Err_stl10,path1_rank+\"stl10-rank100.pt\")  \n",
        "    # torch.save(Err_emp_svhn,path2_rank+\"svhn-emp-rank100.pt\")\n",
        "    # torch.save(Err_svhn,path1_rank+\"svhn-rank100.pt\")    \n",
        "\n",
        "    # torch.save(Err_emp_cifar_alpha,path2_rank+\"cifar-emp-alpha-rank100.pt\")\n",
        "    # torch.save(Err_cifar_alpha,path1_rank+\"cifar-alpha-rank100.pt\")  \n",
        "    # torch.save(Err_cifar_bound,path1_rank+\"cifar-bound-rank100.pt\")  \n",
        "    # torch.save(Err_emp_stl10_alpha,path2_rank+\"stl10-emp-alpha-rank100.pt\")\n",
        "    # torch.save(Err_stl10_alpha,path1_rank+\"stl10-alpha-rank100.pt\")  \n",
        "    # torch.save(Err_stl10_bound,path1_rank+\"stl10-bound-rank100.pt\")  \n",
        "    # torch.save(Err_emp_svhn_alpha,path2_rank+\"svhn-emp-alpha-rank100.pt\")\n",
        "    # torch.save(Err_svhn_alpha,path1_rank+\"svhn-alpha-rank100.pt\")  \n",
        "    # torch.save(Err_svhn_bound,path1_rank+\"svhn-bound-rank100.pt\")   \n",
        "\n",
        "    # torch.save(Err_emp_cifar_outss,path2_rank+\"cifar-emp-outss-rank100.pt\")\n",
        "    # torch.save(Err_cifar_outss,path1_rank+\"cifar-outss-rank100.pt\")  \n",
        "    # torch.save(Err_cifar_bound_outss,path1_rank+\"cifar-bound-outss-rank100.pt\")  \n",
        "    # torch.save(Err_emp_stl10_outss,path2_rank+\"stl10-emp-outss-rank100.pt\")\n",
        "    # torch.save(Err_stl10_outss,path1_rank+\"stl10-outss-rank100.pt\")  \n",
        "    # torch.save(Err_stl10_bound_outss,path1_rank+\"stl10-bound-outss-rank100.pt\")  \n",
        "    # torch.save(Err_emp_svhn_outss,path2_rank+\"svhn-emp-outss-rank100.pt\")\n",
        "    # torch.save(Err_svhn_outss,path1_rank+\"svhn-outss-rank100.pt\")  \n",
        "    # torch.save(Err_svhn_bound_outss,path1_rank+\"svhn-bound-outss-rank100.pt\") \n",
        "\n",
        "    # torch.save(Err_emp_iid_test,path2_rank+\"emp-iid-test-rank100.pt\")\n",
        "    # torch.save(Err_iid_test,path1_rank+\"iid-test-rank100.pt\")\n",
        "    \n",
        "    # torch.save(Err_emp_cifar_reg,path2_rank+\"cifar-emp-reg-rank100.pt\")\n",
        "    # torch.save(Err_cifar_reg,path1_rank+\"cifar-reg-rank100.pt\")\n",
        "    # torch.save(Err_emp_stl10_reg,path2_rank+\"stl10-emp-reg-rank100.pt\")\n",
        "    # torch.save(Err_stl10_reg,path1_rank+\"stl10-reg-rank100.pt\")\n",
        "    # torch.save(Err_emp_svhn_reg,path2_rank+\"svhn-emp-reg-rank100.pt\")\n",
        "    # torch.save(Err_svhn_reg,path1_rank+\"svhn-reg-rank100.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(alpha_cifar)\n",
        "print(alpha_stl10)\n",
        "print(alpha_svhn)\n",
        "\n",
        "torch.save(alpha_cifar,path1_rank+\"alpha_cifar_50_100\")\n",
        "torch.save(alpha_stl10,path1_rank+\"alpha_stl10_50_100\")\n",
        "torch.save(alpha_svhn,path1_rank+\"alpha_svhn_50_100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFrPmAFsBSz1",
        "outputId": "8bed8ea8-4284-493a-b368-8c2a6c3d3d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[56.5374, 55.8675, 55.5930, 55.3770, 55.2432, 55.1558, 55.0763, 55.0220,\n",
            "         54.9711, 54.9341, 54.9081, 54.8787, 54.8567, 54.8306, 54.8190, 54.8026,\n",
            "         54.7910, 54.7807],\n",
            "        [46.3874, 45.3596, 44.9010, 44.5934, 44.3949, 44.2267, 44.1190, 44.0175,\n",
            "         43.9522, 43.8953, 43.8580, 43.8190, 43.7857, 43.7452, 43.7228, 43.6963,\n",
            "         43.6788, 43.6551]], device='cuda:0')\n",
            "tensor([[76.4720, 75.9263, 75.7459, 75.5754, 75.4362, 75.3707, 75.3334, 75.2663,\n",
            "         75.2419, 75.2283, 75.2083, 75.1899, 75.1722, 75.1614, 75.1553, 75.1294,\n",
            "         75.1185, 75.0983],\n",
            "        [67.5094, 66.7972, 66.5428, 66.3103, 66.1776, 66.0538, 65.9800, 65.9153,\n",
            "         65.8495, 65.8033, 65.7698, 65.7455, 65.7289, 65.7119, 65.6847, 65.6665,\n",
            "         65.6522, 65.6447]], device='cuda:0')\n",
            "tensor([[34.1146, 33.2174, 32.7537, 32.4613, 32.1534, 32.1761, 32.0390, 31.8235,\n",
            "         31.7893, 31.6774, 31.6292, 31.6588, 31.6622, 31.5749, 31.5732, 31.5698,\n",
            "         31.5342, 31.5111],\n",
            "        [24.0753, 22.8017, 22.0990, 21.5735, 21.3069, 21.0778, 20.9455, 20.8135,\n",
            "         20.7259, 20.6524, 20.6152, 20.5435, 20.4792, 20.4348, 20.4211, 20.3677,\n",
            "         20.3831, 20.3410]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDzWajEJR6o5",
        "outputId": "f8edf402-9bbc-4c22-d597-c4abc1091355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "torch.Size([3072, 1050]) torch.Size([3072, 525]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0057, device='cuda:0')\n",
            "tensor(0.0058, device='cuda:0')\n",
            "tensor(0.0071, device='cuda:0')\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 800]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:49<00:00,  4.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0063, device='cuda:0')\n",
            "tensor(0.0069, device='cuda:0')\n",
            "tensor(0.0079, device='cuda:0')\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 1075]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [01:34<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0059, device='cuda:0')\n",
            "tensor(0.0065, device='cuda:0')\n",
            "tensor(0.0074, device='cuda:0')\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 1350]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:22<00:00,  1.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0049, device='cuda:0')\n",
            "tensor(0.0042, device='cuda:0')\n",
            "tensor(0.0050, device='cuda:0')\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 1625]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:11<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0013, device='cuda:0')\n",
            "tensor(0.0008, device='cuda:0')\n",
            "tensor(0.0012, device='cuda:0')\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 1900]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:11<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0047, device='cuda:0')\n",
            "tensor(0.0035, device='cuda:0')\n",
            "tensor(0.0044, device='cuda:0')\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2175]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:13<00:00,  1.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0045, device='cuda:0')\n",
            "tensor(0.0043, device='cuda:0')\n",
            "tensor(0.0041, device='cuda:0')\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2450]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:15<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0053, device='cuda:0')\n",
            "tensor(0.0047, device='cuda:0')\n",
            "tensor(0.0047, device='cuda:0')\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2725]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:16<00:00,  1.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0040, device='cuda:0')\n",
            "tensor(0.0042, device='cuda:0')\n",
            "tensor(0.0040, device='cuda:0')\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:18<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0025, device='cuda:0')\n",
            "tensor(0.0027, device='cuda:0')\n",
            "tensor(0.0034, device='cuda:0')\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 3275]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:20<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0035, device='cuda:0')\n",
            "tensor(0.0030, device='cuda:0')\n",
            "tensor(0.0030, device='cuda:0')\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 3550]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:21<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0034, device='cuda:0')\n",
            "tensor(0.0029, device='cuda:0')\n",
            "tensor(0.0032, device='cuda:0')\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 3825]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:22<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0026, device='cuda:0')\n",
            "tensor(0.0029, device='cuda:0')\n",
            "tensor(0.0024, device='cuda:0')\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 4100]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:25<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0031, device='cuda:0')\n",
            "tensor(0.0025, device='cuda:0')\n",
            "tensor(0.0030, device='cuda:0')\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 4375]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0032, device='cuda:0')\n",
            "tensor(0.0025, device='cuda:0')\n",
            "tensor(0.0025, device='cuda:0')\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 4650]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:28<00:00,  1.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0029, device='cuda:0')\n",
            "tensor(0.0023, device='cuda:0')\n",
            "tensor(0.0023, device='cuda:0')\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 4925]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:29<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0028, device='cuda:0')\n",
            "tensor(0.0017, device='cuda:0')\n",
            "tensor(0.0026, device='cuda:0')\n",
            "torch.Size([3072, 10200]) torch.Size([3072, 5200]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:30<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0063, device='cuda:0')\n",
            "tensor(0.0066, device='cuda:0')\n",
            "tensor(0.0054, device='cuda:0')\n",
            "100\n",
            "torch.Size([3072, 1050]) torch.Size([3072, 525]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:25<00:00,  7.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0272, device='cuda:0')\n",
            "tensor(0.0256, device='cuda:0')\n",
            "tensor(0.0296, device='cuda:0')\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 800]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:51<00:00,  3.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0286, device='cuda:0')\n",
            "tensor(0.0278, device='cuda:0')\n",
            "tensor(0.0306, device='cuda:0')\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 1075]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [01:37<00:00,  2.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0300, device='cuda:0')\n",
            "tensor(0.0289, device='cuda:0')\n",
            "tensor(0.0310, device='cuda:0')\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 1350]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:27<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0278, device='cuda:0')\n",
            "tensor(0.0275, device='cuda:0')\n",
            "tensor(0.0290, device='cuda:0')\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 1625]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:21<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0228, device='cuda:0')\n",
            "tensor(0.0227, device='cuda:0')\n",
            "tensor(0.0246, device='cuda:0')\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 1900]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:23<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0244, device='cuda:0')\n",
            "tensor(0.0243, device='cuda:0')\n",
            "tensor(0.0254, device='cuda:0')\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2175]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0213, device='cuda:0')\n",
            "tensor(0.0208, device='cuda:0')\n",
            "tensor(0.0221, device='cuda:0')\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2450]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:29<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0187, device='cuda:0')\n",
            "tensor(0.0186, device='cuda:0')\n",
            "tensor(0.0195, device='cuda:0')\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2725]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:31<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0172, device='cuda:0')\n",
            "tensor(0.0169, device='cuda:0')\n",
            "tensor(0.0179, device='cuda:0')\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:32<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0153, device='cuda:0')\n",
            "tensor(0.0148, device='cuda:0')\n",
            "tensor(0.0157, device='cuda:0')\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 3275]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:34<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0141, device='cuda:0')\n",
            "tensor(0.0137, device='cuda:0')\n",
            "tensor(0.0146, device='cuda:0')\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 3550]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:36<00:00,  1.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0131, device='cuda:0')\n",
            "tensor(0.0132, device='cuda:0')\n",
            "tensor(0.0136, device='cuda:0')\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 3825]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:38<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0119, device='cuda:0')\n",
            "tensor(0.0121, device='cuda:0')\n",
            "tensor(0.0124, device='cuda:0')\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 4100]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:40<00:00,  1.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0112, device='cuda:0')\n",
            "tensor(0.0109, device='cuda:0')\n",
            "tensor(0.0119, device='cuda:0')\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 4375]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:42<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0104, device='cuda:0')\n",
            "tensor(0.0105, device='cuda:0')\n",
            "tensor(0.0106, device='cuda:0')\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 4650]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:44<00:00,  1.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0099, device='cuda:0')\n",
            "tensor(0.0096, device='cuda:0')\n",
            "tensor(0.0102, device='cuda:0')\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 4925]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:45<00:00,  1.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0093, device='cuda:0')\n",
            "tensor(0.0091, device='cuda:0')\n",
            "tensor(0.0094, device='cuda:0')\n",
            "torch.Size([3072, 10200]) torch.Size([3072, 5200]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:46<00:00,  1.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0007, device='cuda:0')\n",
            "tensor(0.0008, device='cuda:0')\n",
            "tensor(0.0010, device='cuda:0')\n",
            "150\n",
            "torch.Size([3072, 1050]) torch.Size([3072, 525]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:25<00:00,  7.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0408, device='cuda:0')\n",
            "tensor(0.0387, device='cuda:0')\n",
            "tensor(0.0453, device='cuda:0')\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 800]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:51<00:00,  3.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0437, device='cuda:0')\n",
            "tensor(0.0422, device='cuda:0')\n",
            "tensor(0.0469, device='cuda:0')\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 1075]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [01:38<00:00,  2.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0449, device='cuda:0')\n",
            "tensor(0.0439, device='cuda:0')\n",
            "tensor(0.0474, device='cuda:0')\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 1350]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:28<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0448, device='cuda:0')\n",
            "tensor(0.0435, device='cuda:0')\n",
            "tensor(0.0466, device='cuda:0')\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 1625]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:25<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0393, device='cuda:0')\n",
            "tensor(0.0390, device='cuda:0')\n",
            "tensor(0.0413, device='cuda:0')\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 1900]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:28<00:00,  1.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0374, device='cuda:0')\n",
            "tensor(0.0365, device='cuda:0')\n",
            "tensor(0.0387, device='cuda:0')\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2175]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:30<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0323, device='cuda:0')\n",
            "tensor(0.0318, device='cuda:0')\n",
            "tensor(0.0333, device='cuda:0')\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2450]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:33<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0288, device='cuda:0')\n",
            "tensor(0.0285, device='cuda:0')\n",
            "tensor(0.0299, device='cuda:0')\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2725]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:34<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0255, device='cuda:0')\n",
            "tensor(0.0254, device='cuda:0')\n",
            "tensor(0.0266, device='cuda:0')\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:36<00:00,  1.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0237, device='cuda:0')\n",
            "tensor(0.0227, device='cuda:0')\n",
            "tensor(0.0240, device='cuda:0')\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 3275]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:39<00:00,  1.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0208, device='cuda:0')\n",
            "tensor(0.0208, device='cuda:0')\n",
            "tensor(0.0220, device='cuda:0')\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 3550]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:41<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0195, device='cuda:0')\n",
            "tensor(0.0193, device='cuda:0')\n",
            "tensor(0.0204, device='cuda:0')\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 3825]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:42<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0184, device='cuda:0')\n",
            "tensor(0.0180, device='cuda:0')\n",
            "tensor(0.0192, device='cuda:0')\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 4100]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:44<00:00,  1.42s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0168, device='cuda:0')\n",
            "tensor(0.0165, device='cuda:0')\n",
            "tensor(0.0176, device='cuda:0')\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 4375]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:47<00:00,  1.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0165, device='cuda:0')\n",
            "tensor(0.0158, device='cuda:0')\n",
            "tensor(0.0168, device='cuda:0')\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 4650]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:48<00:00,  1.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0149, device='cuda:0')\n",
            "tensor(0.0144, device='cuda:0')\n",
            "tensor(0.0156, device='cuda:0')\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 4925]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:50<00:00,  1.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0140, device='cuda:0')\n",
            "tensor(0.0141, device='cuda:0')\n",
            "tensor(0.0147, device='cuda:0')\n",
            "torch.Size([3072, 10200]) torch.Size([3072, 5200]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:51<00:00,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0052, device='cuda:0')\n",
            "tensor(0.0049, device='cuda:0')\n",
            "tensor(0.0054, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from numpy.lib.arraysetops import setxor1d\n",
        "## Non-identical data augmentation experiments\n",
        "\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int)\n",
        "#r_values = [1,2,3,5,10,20,50,100,150,200,250]\n",
        "#r_values = [50]\n",
        "r_values = [25,100,150]\n",
        "# N = torch.arange(500,1000,500)\n",
        "# r_values = [1,100]\n",
        "Ntst = 2500\n",
        "\n",
        "Err_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #emperical error \n",
        "\n",
        "# print(Err_svhn.shape)\n",
        "\n",
        "\n",
        "# bias = torch.zeros(len(r_values),N.shape[0])\n",
        "# var = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "# bias_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "# var_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "T = 200 #Number of runs\n",
        "\n",
        "for i,r in list(enumerate(r_values)):\n",
        "  print(r)\n",
        "  for j in range(N.shape[0]):\n",
        "    c = M/N[j]\n",
        "    cifar_train_data = torch.utils.data.DataLoader(cifar_train, batch_size = (N[j]//2).item(), shuffle = False)\n",
        "    Xtrn_cifar = next(iter(cifar_train_data))[0].T\n",
        "\n",
        "    stl10_data = torch.utils.data.DataLoader(stl10_train, batch_size = (N[j]//2).item(), shuffle = False)\n",
        "    Xtrn_stl10 = next(iter(stl10_data))[0].T\n",
        "\n",
        "    Xtrn = torch.cat((Xtrn_cifar,Xtrn_stl10),1) ##concatenating the training data for order d x N\n",
        "\n",
        "    cifar_test_data = torch.utils.data.DataLoader(cifar_test, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_cifar = next(iter(cifar_test_data))[0].T\n",
        "\n",
        "    stl10_test_data = torch.utils.data.DataLoader(stl10_test, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_stl10 = next(iter(stl10_test_data))[0].T\n",
        "\n",
        "    svhn_data = torch.utils.data.DataLoader(svhn_train, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_svhn = next(iter(svhn_data))[0].T\n",
        "\n",
        "    print(Xtrn.shape, Xtrn_cifar.shape, Xtst_stl10.shape)\n",
        "\n",
        "    print(c)\n",
        "    U,S,Vh = torch.linalg.svd(Xtrn)\n",
        "    Xtrn = U[:,:r] @ torch.diag(S[:r]) @ Vh[:r,:]\n",
        "\n",
        "    P = U[:,:r] @ U[:,:r].T\n",
        "\n",
        "    Xtst_cifar_proj = P @ Xtst_cifar\n",
        "    Xtst_stl10_proj = P @ Xtst_stl10\n",
        "    Xtst_svhn_proj = P @ Xtst_svhn\n",
        "\n",
        "    L_cifar = U[:,:r].T @ Xtst_cifar\n",
        "    L_stl10 = U[:,:r].T @ Xtst_stl10\n",
        "    L_svhn = U[:,:r].T @ Xtst_svhn\n",
        "\n",
        "    Err_cifar[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_cifar)\n",
        "    Err_stl10[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_stl10)\n",
        "    Err_svhn[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_svhn)\n",
        "\n",
        "    # wnorm = calc_wnorm(c,r,S[:r])\n",
        "    # emp_norm = 0\n",
        "    # emp_bias = 0\n",
        "    # bias = (torch.diag(1/(1+S[:r].square())) @ L_cifar).square().sum()\n",
        "    \n",
        "    for k in tqdm(range(T)):\n",
        "        Atrn = torch.randn_like(Xtrn)/np.sqrt(M)\n",
        "        W = Xtrn.mm(torch.pinverse(Xtrn+Atrn))\n",
        "\n",
        "        # emp_norm += W.square().sum()/T\n",
        "\n",
        "        Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "        Err_emp_cifar[i,j] += (Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "        # emp_bias += (Xtst_cifar_proj - W @ Xtst_cifar_proj).square().sum()/T\n",
        "\n",
        "        Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "        Err_emp_stl10[i,j] += (Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "        Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "        Err_emp_svhn[i,j] += (Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "    # print(wnorm, bias)\n",
        "    # print(emp_norm, emp_bias)\n",
        "    \n",
        "    print((Err_emp_cifar[i,j]-Err_cifar[i,j]).abs()/Err_emp_cifar[i,j])\n",
        "    print((Err_emp_stl10[i,j]-Err_stl10[i,j]).abs()/Err_emp_stl10[i,j])\n",
        "    print((Err_emp_svhn[i,j]-Err_svhn[i,j]).abs()/Err_emp_svhn[i,j])\n",
        "\n",
        "    torch.save(Err_emp_cifar,path2_rank+\"cifar-emp-nonIdentical-ranks.pt\")\n",
        "    torch.save(Err_cifar,path1_rank+\"cifar-nonIdentical-ranks.pt\")  \n",
        "    torch.save(Err_emp_stl10,path2_rank+\"stl10-emp-nonIdentical-ranks.pt\")\n",
        "    torch.save(Err_stl10,path1_rank+\"stl10-nonIdentical-ranks.pt\")  \n",
        "    torch.save(Err_emp_svhn,path2_rank+\"svhn-emp-nonIdentical-ranks.pt\")\n",
        "    torch.save(Err_svhn,path1_rank+\"svhn-nonIdentical-ranks.pt\")    \n",
        "\n",
        "  # Error_stack = torch.cat((Error_stack,Err_cifar[i,:].unsqueeze(0)),0)\n",
        "  # Error_emp_stack = torch.cat((Error_emp_stack,Err_emp_cifar[i,:].unsqueeze(0)),0)\n",
        "  \n",
        "  # torch.save(Error_stack,path1_new_new)\n",
        "  # torch.save(Error_emp_stack,path2_new_new)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooMl-JF_5zd3"
      },
      "outputs": [],
      "source": [
        "from numpy.lib.arraysetops import setxor1d\n",
        "## Data augmentation for multiple r values\n",
        "\n",
        "M = 3072\n",
        "#N = torch.arange(1000,6000,1000).to(torch.int) #for empirical values\n",
        "\n",
        "N = torch.arange(1000,6000,50).to(torch.int) ##more c values for smoother theory curves\n",
        "#r_values = [1,2,3,5,10,20,50,100,150,200,250]\n",
        "#r_values = [50]\n",
        "r_values = [25,100,150]\n",
        "theta_values = torch.tensor([1])\n",
        "# N = torch.arange(500,1000,500)\n",
        "# r_values = [1,100]\n",
        "Ntst = 2500\n",
        "\n",
        "Err_stl10 = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10 = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]//20).to(device) #emperical error \n",
        "\n",
        "Err_svhn = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]//20).to(device) #emperical error \n",
        "\n",
        "Err_cifar = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]//20).to(device) #emperical error \n",
        "print(Err_stl10.shape)\n",
        "\n",
        "\n",
        "# bias = torch.zeros(len(r_values),N.shape[0])\n",
        "# var = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "# bias_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "# var_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "#Number of runs\n",
        "T =200\n",
        "\n",
        "for i,r in list(enumerate(r_values)):\n",
        "  for j,_ in enumerate(theta_values):\n",
        "    theta = 1\n",
        "    print(r,theta)\n",
        "    T = 500\n",
        "    for k in range(N.shape[0]):\n",
        "      c = M/N[k]\n",
        "      cifar_data = torch.utils.data.DataLoader(cifar_train, batch_size = N[0].item(), shuffle = False)\n",
        "      batch = next(iter(cifar_data))[0].T\n",
        "      Xtrn = torch.clone(batch)\n",
        "      # for _ in range(k):\n",
        "      #   Xtrn = torch.cat((Xtrn,batch),dim=1)\n",
        "\n",
        "      cifar_test_data = torch.utils.data.DataLoader(cifar_test, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_cifar = next(iter(cifar_test_data))[0].T\n",
        "\n",
        "      stl10_data = torch.utils.data.DataLoader(stl10_train, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_stl10 = next(iter(stl10_data))[0].T\n",
        "\n",
        "      svhn_data = torch.utils.data.DataLoader(svhn_train, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_svhn = next(iter(svhn_data))[0].T\n",
        "\n",
        "      print(Xtrn.shape, Xtst_cifar.shape)\n",
        "\n",
        "      print(c)\n",
        "      U,S,Vh = torch.linalg.svd(Xtrn)\n",
        "      Xtrn = theta * U[:,:r] @ torch.diag(S[:r]) @ Vh[:r,:]\n",
        "\n",
        "      P = U[:,:r] @ U[:,:r].T\n",
        "\n",
        "      Xtst_cifar_proj = P @ Xtst_cifar\n",
        "      Xtst_stl10_proj = P @ Xtst_stl10\n",
        "      Xtst_svhn_proj = P @ Xtst_svhn\n",
        "\n",
        "      # L_cifar = U[:,:r].T @ Xtst_cifar\n",
        "      # L_stl10 = U[:,:r].T @ Xtst_stl10\n",
        "      # L_svhn = U[:,:r].T @ Xtst_svhn\n",
        "\n",
        "      # Err_cifar[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_cifar)\n",
        "      # Err_stl10[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_stl10)\n",
        "      # Err_svhn[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_svhn)\n",
        "\n",
        "      if k%20 == 0:\n",
        "        for _ in range(k//20):\n",
        "          Xtrn = torch.cat((Xtrn,batch),dim=1)\n",
        "\n",
        "        for _ in tqdm(range(T)):\n",
        "          Atrn = torch.randn_like(Xtrn)/np.sqrt(M)\n",
        "          W = Xtrn.mm(torch.pinverse(Xtrn+Atrn))\n",
        "\n",
        "          Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "          Err_emp_cifar[i,j,k//20] += (Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "          Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "          Err_emp_stl10[i,j,k//20] += (Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "          Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "          Err_emp_svhn[i,j,k//20] += (Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "      \n",
        "      # print((Err_emp_cifar[i,j,k]-Err_cifar[i,j,k]).abs()/Err_emp_cifar[i,j,k])\n",
        "      # print((Err_emp_stl10[i,j,k]-Err_stl10[i,j,k]).abs()/Err_emp_stl10[i,j,k])\n",
        "      # print((Err_emp_svhn[i,j,k]-Err_svhn[i,j,k]).abs()/Err_emp_svhn[i,j,k])\n",
        "\n",
        "        print(Err_emp_cifar[i,j,k//20])\n",
        "        print(Err_emp_stl10[i,j,k//20])\n",
        "        print(Err_emp_svhn[i,j,k//20])\n",
        "\n",
        "      torch.save(Err_emp_cifar,path2_rank+\"-data-aug-cifar-emp-ranks.pt\")\n",
        "      # torch.save(Err_cifar,path1_rank+\"-data-aug-cifar-ranks.pt\")  \n",
        "      torch.save(Err_emp_stl10,path2_rank+\"-data-aug-stl10-emp-ranks.pt\")\n",
        "      # torch.save(Err_stl10,path1_rank+\"-data-aug-stl10-ranks.pt\")  \n",
        "      torch.save(Err_emp_svhn,path2_rank+\"-data-aug-svhn-emp-ranks.pt\")\n",
        "      # torch.save(Err_svhn,path1_rank+\"-data-aug-svhn-ranks.pt\")    \n",
        "\n",
        "\n",
        "  # Error_stack = torch.cat((Error_stack,Err_cifar[i,:].unsqueeze(0)),0)\n",
        "  # Error_emp_stack = torch.cat((Error_emp_stack,Err_emp_cifar[i,:].unsqueeze(0)),0)\n",
        "  \n",
        "  # torch.save(Error_stack,path1_new_new)\n",
        "  # torch.save(Error_emp_stack,path2_new_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MZghcspnbnv",
        "outputId": "208e2e36-0d69-4f6f-d51c-6d5d6b60d108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 5])\n",
            "25 1\n",
            "torch.Size([3072, 1000]) torch.Size([3072, 2500])\n",
            "tensor(3.0720, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:52<00:00,  9.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0120, device='cuda:0')\n",
            "tensor(0.0120, device='cuda:0')\n",
            "tensor(0.0120, device='cuda:0')\n",
            "torch.Size([3072, 2000]) torch.Size([3072, 2500])\n",
            "tensor(1.5360, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [03:11<00:00,  2.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0232, device='cuda:0')\n",
            "tensor(0.0232, device='cuda:0')\n",
            "tensor(0.0232, device='cuda:0')\n",
            "torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(1.0240, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:32<00:00,  1.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3484, device='cuda:0')\n",
            "tensor(0.3485, device='cuda:0')\n",
            "tensor(0.3484, device='cuda:0')\n",
            "torch.Size([3072, 4000]) torch.Size([3072, 2500])\n",
            "tensor(0.7680, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:23<00:00,  1.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0349, device='cuda:0')\n",
            "tensor(0.0349, device='cuda:0')\n",
            "tensor(0.0349, device='cuda:0')\n",
            "torch.Size([3072, 5000]) torch.Size([3072, 2500])\n",
            "tensor(0.6144, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:30<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0210, device='cuda:0')\n",
            "tensor(0.0210, device='cuda:0')\n",
            "tensor(0.0210, device='cuda:0')\n",
            "100 1\n",
            "torch.Size([3072, 1000]) torch.Size([3072, 2500])\n",
            "tensor(3.0720, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:54<00:00,  9.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0468, device='cuda:0')\n",
            "tensor(0.0468, device='cuda:0')\n",
            "tensor(0.0467, device='cuda:0')\n",
            "torch.Size([3072, 2000]) torch.Size([3072, 2500])\n",
            "tensor(1.5360, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [03:19<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0903, device='cuda:0')\n",
            "tensor(0.0904, device='cuda:0')\n",
            "tensor(0.0903, device='cuda:0')\n",
            "torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(1.0240, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:46<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.3615, device='cuda:0')\n",
            "tensor(1.3615, device='cuda:0')\n",
            "tensor(1.3604, device='cuda:0')\n",
            "torch.Size([3072, 4000]) torch.Size([3072, 2500])\n",
            "tensor(0.7680, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:47<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1369, device='cuda:0')\n",
            "tensor(0.1369, device='cuda:0')\n",
            "tensor(0.1369, device='cuda:0')\n",
            "torch.Size([3072, 5000]) torch.Size([3072, 2500])\n",
            "tensor(0.6144, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:56<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0827, device='cuda:0')\n",
            "tensor(0.0827, device='cuda:0')\n",
            "tensor(0.0827, device='cuda:0')\n",
            "150 1\n",
            "torch.Size([3072, 1000]) torch.Size([3072, 2500])\n",
            "tensor(3.0720, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:55<00:00,  8.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0690, device='cuda:0')\n",
            "tensor(0.0690, device='cuda:0')\n",
            "tensor(0.0688, device='cuda:0')\n",
            "torch.Size([3072, 2000]) torch.Size([3072, 2500])\n",
            "tensor(1.5360, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [03:21<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1332, device='cuda:0')\n",
            "tensor(0.1333, device='cuda:0')\n",
            "tensor(0.1331, device='cuda:0')\n",
            "torch.Size([3072, 3000]) torch.Size([3072, 2500])\n",
            "tensor(1.0240, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:50<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.0106, device='cuda:0')\n",
            "tensor(2.0116, device='cuda:0')\n",
            "tensor(2.0095, device='cuda:0')\n",
            "torch.Size([3072, 4000]) torch.Size([3072, 2500])\n",
            "tensor(0.7680, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [07:53<00:00,  1.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2027, device='cuda:0')\n",
            "tensor(0.2027, device='cuda:0')\n",
            "tensor(0.2025, device='cuda:0')\n",
            "torch.Size([3072, 5000]) torch.Size([3072, 2500])\n",
            "tensor(0.6144, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [08:01<00:00,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1227, device='cuda:0')\n",
            "tensor(0.1228, device='cuda:0')\n",
            "tensor(0.1227, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from numpy.lib.arraysetops import setxor1d\n",
        "## Low SNR error \n",
        "\n",
        "M = 3072\n",
        "N = torch.arange(1000,6000,1000).to(torch.int)\n",
        "#r_values = [1,2,3,5,10,20,50,100,150,200,250]\n",
        "#r_values = [50]\n",
        "r_values = [25,100,150]\n",
        "theta_values = torch.tensor([1])\n",
        "# N = torch.arange(500,1000,500)\n",
        "# r_values = [1,100]\n",
        "Ntst = 2500\n",
        "\n",
        "Err_stl10 = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10 = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_svhn = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #emperical error \n",
        "\n",
        "Err_cifar = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar = torch.zeros(len(r_values),theta_values.shape[0],N.shape[0]).to(device) #emperical error \n",
        "print(Err_stl10.shape)\n",
        "\n",
        "\n",
        "# bias = torch.zeros(len(r_values),N.shape[0])\n",
        "# var = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "# bias_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "# var_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "#Number of runs\n",
        "T = 500\n",
        "\n",
        "for i,r in list(enumerate(r_values)):\n",
        "  for j,_ in enumerate(theta_values):\n",
        "    theta = 1\n",
        "    print(r,theta)\n",
        "    \n",
        "    for k in range(N.shape[0]):\n",
        "      c = M/N[k]\n",
        "      cifar_data = torch.utils.data.DataLoader(cifar_train, batch_size = N[0].item(), shuffle = False)\n",
        "      batch = next(iter(cifar_data))[0].T\n",
        "      Xtrn = torch.clone(batch)\n",
        "      for _ in range(k):\n",
        "        Xtrn = torch.cat((Xtrn,batch),dim=1)\n",
        "\n",
        "      cifar_test_data = torch.utils.data.DataLoader(cifar_test, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_cifar = next(iter(cifar_test_data))[0].T\n",
        "\n",
        "      stl10_data = torch.utils.data.DataLoader(stl10_train, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_stl10 = next(iter(stl10_data))[0].T\n",
        "\n",
        "      svhn_data = torch.utils.data.DataLoader(svhn_train, batch_size = Ntst, shuffle = False)\n",
        "      Xtst_svhn = next(iter(svhn_data))[0].T\n",
        "\n",
        "      print(Xtrn.shape, Xtst_cifar.shape)\n",
        "\n",
        "      print(c)\n",
        "      U,S,Vh = torch.linalg.svd(Xtrn)\n",
        "      Xtrn = theta * U[:,:r] @ torch.diag(S[:r]) @ Vh[:r,:]\n",
        "\n",
        "      P = U[:,:r] @ U[:,:r].T\n",
        "\n",
        "      Xtst_cifar_proj = P @ Xtst_cifar\n",
        "      Xtst_stl10_proj = P @ Xtst_stl10\n",
        "      Xtst_svhn_proj = P @ Xtst_svhn\n",
        "\n",
        "      # L_cifar = U[:,:r].T @ Xtst_cifar\n",
        "      # L_stl10 = U[:,:r].T @ Xtst_stl10\n",
        "      # L_svhn = U[:,:r].T @ Xtst_svhn\n",
        "\n",
        "      # Err_cifar[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_cifar)\n",
        "      # Err_stl10[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_stl10)\n",
        "      # Err_svhn[i,j,k] = calc_gen_error(M,N[k],c,Ntst,r,theta*S[:r],L_svhn)\n",
        "      \n",
        "      for _ in tqdm(range(T)):\n",
        "          Atrn = torch.randn_like(Xtrn)/np.sqrt(M)\n",
        "          W = Xtrn.mm(torch.pinverse(Xtrn+Atrn))\n",
        "\n",
        "          Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "          Err_emp_cifar[i,j,k] += (Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "          Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "          Err_emp_stl10[i,j,k] += (Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "          Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "          Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "          Err_emp_svhn[i,j,k] += (Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "      \n",
        "      # print((Err_emp_cifar[i,j,k]-Err_cifar[i,j,k]).abs()/Err_emp_cifar[i,j,k])\n",
        "      # print((Err_emp_stl10[i,j,k]-Err_stl10[i,j,k]).abs()/Err_emp_stl10[i,j,k])\n",
        "      # print((Err_emp_svhn[i,j,k]-Err_svhn[i,j,k]).abs()/Err_emp_svhn[i,j,k])\n",
        "\n",
        "      print(Err_emp_cifar[i,j,k])\n",
        "      print(Err_emp_stl10[i,j,k])\n",
        "      print(Err_emp_svhn[i,j,k])\n",
        "\n",
        "      # torch.save(Err_emp_cifar,path2_new_new+\"-data-aug-cifar-emp.pt\")\n",
        "      # torch.save(Err_cifar,path1_new_new+\"-data-aug-cifar.pt\")  \n",
        "      # torch.save(Err_emp_stl10,path2_new_new+\"-data-aug-stl10-emp.pt\")\n",
        "      # torch.save(Err_stl10,path1_new_new+\"-data-aug-stl10.pt\")  \n",
        "      # torch.save(Err_emp_svhn,path2_new_new+\"-data-aug-svhn-emp.pt\")\n",
        "      # torch.save(Err_svhn,path1_new_new+\"-data-aug-svhn.pt\")    \n",
        "\n",
        "      torch.save(Err_emp_cifar,path2_rank+\"-data-aug-cifar-emp-ranks.pt\")\n",
        "      # torch.save(Err_cifar,path1_rank+\"-data-aug-cifar-ranks.pt\")  \n",
        "      torch.save(Err_emp_stl10,path2_rank+\"-data-aug-stl10-emp-ranks.pt\")\n",
        "      # torch.save(Err_stl10,path1_rank+\"-data-aug-stl10-ranks.pt\")  \n",
        "      torch.save(Err_emp_svhn,path2_rank+\"-data-aug-svhn-emp-ranks.pt\")\n",
        "      # torch.save(Err_svhn,path1_rank+\"-data-aug-svhn-ranks.pt\")    \n",
        "\n",
        "\n",
        "  # Error_stack = torch.cat((Error_stack,Err_cifar[i,:].unsqueeze(0)),0)\n",
        "  # Error_emp_stack = torch.cat((Error_emp_stack,Err_emp_cifar[i,:].unsqueeze(0)),0)\n",
        "  \n",
        "  # torch.save(Error_stack,path1_new_new)\n",
        "  # torch.save(Error_emp_stack,path2_new_new)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41qjWCbfWVQH",
        "outputId": "bdb9b084-b9b1-4940-bfed-0a735838653b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0137, 0.0148, 0.0138, 0.0131, 0.0097, 0.0111, 0.0106, 0.0089, 0.0084,\n",
            "         0.0078, 0.0079, 0.0068, 0.0067, 0.0049, 0.0054, 0.0051, 0.0049, 0.0035]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print((Err_emp_svhn-Err_svhn).abs()/Err_emp_svhn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq9pKl9xXyI1"
      },
      "outputs": [],
      "source": [
        "plt.rc('font',size=20)\n",
        "plt.rc('xtick', labelsize=14) \n",
        "plt.rc('ytick', labelsize=14)\n",
        "plt.rc('legend',fontsize=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "cagwPbeyWa1w",
        "outputId": "831c7340-70ca-42bf-8ce9-a0e1ca7030d3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "path_figures = F\"/content/drive/My Drive/Denoising/figures/\"\n",
        "\n",
        "device = 'cpu'\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int).cpu()\n",
        "#N_theory = torch.arange(500,6010,55).to(torch.int)\n",
        "\n",
        "Cinverse = (N/M).cpu().numpy()\n",
        "#Cinverse_theory = (N_theory/M).cpu().numpy()\n",
        "# Err_emp_iid_both = torch.load(path2_new_new+\"iid-both-emp.pt\",map_location = device).numpy()\n",
        "# Err_iid_both = torch.load(path1_figures+\"iid-both.pt\",map_location = device).numpy()\n",
        "\n",
        "plt.plot(Cinverse,Err_svhn[0,:].cpu().numpy(),color=\"red\")\n",
        "plt.plot(Cinverse,Err_emp_svhn[0,:].cpu().numpy(),'.',markersize = 15,color=\"red\")\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"1/c = N/d\")\n",
        "plt.ylabel(\"Generalization Error\")\n",
        "plt.legend(['Theoretical Result','Empirical Result'],fontsize=13.5)\n",
        "#plt.title('CIFAR Dataset')\n",
        "plt.savefig(path_figures+\"non-identical-svhn-error.pdf\", bbox_inches='tight', facecolor='white', dpi = 300, format = 'pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAJ_NmAtoGIS",
        "outputId": "da7b6556-a8e9-4ada-cde6-a179d292f69c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1050, 1600, 2150, 2700], device='cuda:0', dtype=torch.int32)\n",
            "tensor([ 3250,  3800,  4350,  4900,  5450,  6000,  6550,  7100,  7650,  8200,\n",
            "         8750,  9300,  9850, 10400], device='cuda:0', dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "N = torch.arange(1050,3250,550).to(torch.int)\n",
        "print(N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3CCtGkPG3BD",
        "outputId": "3cff11a6-6a1c-481b-a300-b9d9e90fb9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 18])\n",
            "r= tensor(1050, device='cuda:0', dtype=torch.int32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3072, 1050]) torch.Size([3072, 2500])\n",
            "tensor(2.9257, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:48<00:00,  4.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2399, device='cuda:0')\n",
            "tensor(0.1584, device='cuda:0')\n",
            "tensor(0.2908, device='cuda:0')\n",
            "r= tensor(1600, device='cuda:0', dtype=torch.int32)\n",
            "torch.Size([3072, 1600]) torch.Size([3072, 2500])\n",
            "tensor(1.9200, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [02:12<00:00,  1.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3699, device='cuda:0')\n",
            "tensor(0.2188, device='cuda:0')\n",
            "tensor(0.4343, device='cuda:0')\n",
            "r= tensor(2150, device='cuda:0', dtype=torch.int32)\n",
            "torch.Size([3072, 2150]) torch.Size([3072, 2500])\n",
            "tensor(1.4288, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [05:16<00:00,  1.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4972, device='cuda:0')\n",
            "tensor(0.2772, device='cuda:0')\n",
            "tensor(0.5675, device='cuda:0')\n",
            "r= tensor(2700, device='cuda:0', dtype=torch.int32)\n",
            "torch.Size([3072, 2700]) torch.Size([3072, 2500])\n",
            "tensor(1.1378, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [10:38<00:00,  3.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6170, device='cuda:0')\n",
            "tensor(0.3359, device='cuda:0')\n",
            "tensor(0.6889, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 3250]) torch.Size([3072, 2500])\n",
            "tensor(0.9452, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [13:38<00:00,  4.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6422, device='cuda:0')\n",
            "tensor(0.3514, device='cuda:0')\n",
            "tensor(0.7065, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 3800]) torch.Size([3072, 2500])\n",
            "tensor(0.8084, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [13:50<00:00,  4.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5353, device='cuda:0')\n",
            "tensor(0.3168, device='cuda:0')\n",
            "tensor(0.5812, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 4350]) torch.Size([3072, 2500])\n",
            "tensor(0.7062, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:00<00:00,  4.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.4532, device='cuda:0')\n",
            "tensor(0.2799, device='cuda:0')\n",
            "tensor(0.4881, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 4900]) torch.Size([3072, 2500])\n",
            "tensor(0.6269, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:09<00:00,  4.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3922, device='cuda:0')\n",
            "tensor(0.2493, device='cuda:0')\n",
            "tensor(0.4200, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 5450]) torch.Size([3072, 2500])\n",
            "tensor(0.5637, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:13<00:00,  4.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3471, device='cuda:0')\n",
            "tensor(0.2265, device='cuda:0')\n",
            "tensor(0.3704, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 6000]) torch.Size([3072, 2500])\n",
            "tensor(0.5120, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:22<00:00,  4.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3101, device='cuda:0')\n",
            "tensor(0.2057, device='cuda:0')\n",
            "tensor(0.3297, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 6550]) torch.Size([3072, 2500])\n",
            "tensor(0.4690, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:28<00:00,  4.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2814, device='cuda:0')\n",
            "tensor(0.1894, device='cuda:0')\n",
            "tensor(0.2984, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 7100]) torch.Size([3072, 2500])\n",
            "tensor(0.4327, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:32<00:00,  4.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2574, device='cuda:0')\n",
            "tensor(0.1755, device='cuda:0')\n",
            "tensor(0.2725, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 7650]) torch.Size([3072, 2500])\n",
            "tensor(0.4016, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:39<00:00,  4.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2370, device='cuda:0')\n",
            "tensor(0.1632, device='cuda:0')\n",
            "tensor(0.2504, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 8200]) torch.Size([3072, 2500])\n",
            "tensor(0.3746, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:47<00:00,  4.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2193, device='cuda:0')\n",
            "tensor(0.1519, device='cuda:0')\n",
            "tensor(0.2312, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 8750]) torch.Size([3072, 2500])\n",
            "tensor(0.3511, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:51<00:00,  4.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2040, device='cuda:0')\n",
            "tensor(0.1422, device='cuda:0')\n",
            "tensor(0.2149, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 9300]) torch.Size([3072, 2500])\n",
            "tensor(0.3303, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [14:55<00:00,  4.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1907, device='cuda:0')\n",
            "tensor(0.1339, device='cuda:0')\n",
            "tensor(0.2009, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 9850]) torch.Size([3072, 2500])\n",
            "tensor(0.3119, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [15:03<00:00,  4.52s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1792, device='cuda:0')\n",
            "tensor(0.1263, device='cuda:0')\n",
            "tensor(0.1884, device='cuda:0')\n",
            "r= 3072\n",
            "torch.Size([3072, 10400]) torch.Size([3072, 2500])\n",
            "tensor(0.2954, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [15:10<00:00,  4.55s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1688, device='cuda:0')\n",
            "tensor(0.1195, device='cuda:0')\n",
            "tensor(0.1773, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        " from numpy.lib.arraysetops import setxor1d\n",
        "## Low SNR error \n",
        "\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int)\n",
        "#r_values = [1,2,3,5,10,20,50,100,150,200,250]\n",
        "#r_values = [50]\n",
        "#r_values = N\n",
        "# N = torch.arange(500,1000,500)\n",
        "# r_values = [1,100]\n",
        "Ntst = 2500\n",
        "\n",
        "# Err_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "# Err_emp_stl10 = torch.zeros(len(r_values),N.shape[0]).to(device) #empirical error \n",
        "\n",
        "# Err_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "# Err_emp_svhn = torch.zeros(len(r_values),N.shape[0]).to(device) #empirical error \n",
        "\n",
        "# Err_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #theoretical error\n",
        "# Err_emp_cifar = torch.zeros(len(r_values),N.shape[0]).to(device) #empirical error \n",
        "# print(Err_stl10.shape)\n",
        "\n",
        "\n",
        "Err_stl10 = torch.zeros(1,N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_stl10 = torch.zeros(1,N.shape[0]).to(device) #empirical error \n",
        "\n",
        "Err_svhn = torch.zeros(1,N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_svhn = torch.zeros(1,N.shape[0]).to(device) #empirical error \n",
        "\n",
        "Err_cifar = torch.zeros(1,N.shape[0]).to(device) #theoretical error\n",
        "Err_emp_cifar = torch.zeros(1,N.shape[0]).to(device) #empirical error \n",
        "print(Err_stl10.shape)\n",
        "\n",
        "# bias = torch.zeros(len(r_values),N.shape[0])\n",
        "# var = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "# bias_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "# var_emp = torch.zeros(len(r_values),N.shape[0])\n",
        "\n",
        "T = 200 #Number of runs\n",
        "\n",
        "# for i,r in list(enumerate(r_values)):\n",
        "#   print(r)\n",
        "\n",
        "i = 0\n",
        "\n",
        "for j in range(N.shape[0]):\n",
        "    r = min(M,N[j])\n",
        "    print(\"r=\",r)\n",
        "    c = M/N[j]\n",
        "    \n",
        "    cifar_data = torch.utils.data.DataLoader(cifar_train, batch_size = N[j].item(), shuffle = False)\n",
        "    Xtrn = next(iter(cifar_data))[0].T\n",
        "\n",
        "    cifar_test_data = torch.utils.data.DataLoader(cifar_test, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_cifar = next(iter(cifar_test_data))[0].T\n",
        "\n",
        "    stl10_data = torch.utils.data.DataLoader(stl10_train, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_stl10 = next(iter(stl10_data))[0].T\n",
        "\n",
        "    svhn_data = torch.utils.data.DataLoader(svhn_train, batch_size = Ntst, shuffle = False)\n",
        "    Xtst_svhn = next(iter(svhn_data))[0].T\n",
        "\n",
        "    print(Xtrn.shape, Xtst_cifar.shape)\n",
        "\n",
        "    print(c)\n",
        "    U,S,Vh = torch.linalg.svd(Xtrn)\n",
        "    Xtrn = U[:,:r] @ torch.diag(S[:r]) @ Vh[:r,:]\n",
        "\n",
        "    P = U[:,:r] @ U[:,:r].T\n",
        "\n",
        "    Xtst_cifar_proj = P @ Xtst_cifar\n",
        "    Xtst_stl10_proj = P @ Xtst_stl10\n",
        "    Xtst_svhn_proj = P @ Xtst_svhn\n",
        "\n",
        "    L_cifar = U[:,:r].T @ Xtst_cifar\n",
        "    L_stl10 = U[:,:r].T @ Xtst_stl10\n",
        "    L_svhn = U[:,:r].T @ Xtst_svhn\n",
        "\n",
        "    Err_cifar[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_cifar)\n",
        "    Err_stl10[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_stl10)\n",
        "    Err_svhn[i,j] = calc_gen_error(M,N[j],c,Ntst,r,S[:r],L_svhn)\n",
        "\n",
        "    wnorm = calc_wnorm(c,r,S[:r])\n",
        "    emp_norm = 0\n",
        "    emp_bias = 0\n",
        "    bias = (torch.diag(1/(1+S[:r].square())) @ L_cifar).square().sum()\n",
        "    \n",
        "    for k in tqdm(range(T)):\n",
        "        Atrn = torch.randn_like(Xtrn)/np.sqrt(M)\n",
        "        W = Xtrn.mm(torch.pinverse(Xtrn+Atrn))\n",
        "\n",
        "        # emp_norm += W.square().sum()/T\n",
        "\n",
        "        Atst_cifar = torch.randn_like(Xtst_cifar_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_cifar_proj + Atst_cifar)\n",
        "        Err_emp_cifar[i,j] += (Xtst_cifar_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "        # emp_bias += (Xtst_cifar_proj - W @ Xtst_cifar_proj).square().sum()/T\n",
        "\n",
        "        Atst_stl10 = torch.randn_like(Xtst_stl10_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_stl10_proj + Atst_stl10)\n",
        "        Err_emp_stl10[i,j] += (Xtst_stl10_proj - Yp).square().sum()/(T*Ntst)\n",
        "\n",
        "        Atst_svhn = torch.randn_like(Xtst_svhn_proj)/np.sqrt(M)\n",
        "        Yp = W.mm(Xtst_svhn_proj + Atst_svhn)\n",
        "        Err_emp_svhn[i,j] += (Xtst_svhn_proj - Yp).square().sum()/(T*Ntst)\n",
        "    # print(wnorm, bias)\n",
        "    # print(emp_norm, emp_bias)\n",
        "    \n",
        "    print((Err_emp_cifar[i,j]-Err_cifar[i,j]).abs()/Err_emp_cifar[i,j])\n",
        "    print((Err_emp_stl10[i,j]-Err_stl10[i,j]).abs()/Err_emp_stl10[i,j])\n",
        "    print((Err_emp_svhn[i,j]-Err_svhn[i,j]).abs()/Err_emp_svhn[i,j])\n",
        "\n",
        "    # torch.save(Err_emp_cifar,path2+\"cifar-emp-highR.pt\")\n",
        "    # torch.save(Err_cifar,path1+\"cifar-highR.pt\")  \n",
        "    # torch.save(Err_emp_stl10,path2+\"stl10-emp-highR.pt\")\n",
        "    # torch.save(Err_stl10,path1+\"stl10-highR.pt\")  \n",
        "    # torch.save(Err_emp_svhn,path2+\"svhn-emp-highR.pt\")\n",
        "    # torch.save(Err_svhn,path1+\"svhn-highR.pt\")   \n",
        "\n",
        "    torch.save(Err_emp_cifar,path2+\"cifar-emp-fullR.pt\")\n",
        "    torch.save(Err_cifar,path1+\"cifar-fullR.pt\")  \n",
        "    torch.save(Err_emp_stl10,path2+\"stl10-emp-fullR.pt\")\n",
        "    torch.save(Err_stl10,path1+\"stl10-fullR.pt\")  \n",
        "    torch.save(Err_emp_svhn,path2+\"svhn-emp-fullR.pt\")\n",
        "    torch.save(Err_svhn,path1+\"svhn-fullR.pt\")  \n",
        "\n",
        "\n",
        "    \n",
        "  # Error_stack = torch.cat((Error_stack,Err_cifar[i,:].unsqueeze(0)),0)\n",
        "  # Error_emp_stack = torch.cat((Error_emp_stack,Err_emp_cifar[i,:].unsqueeze(0)),0)\n",
        "  \n",
        "  # torch.save(Error_stack,path1_new_new)\n",
        "  # torch.save(Error_emp_stack,path2_new_new)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOdBRizvnZaI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVk_4mVADMLw"
      },
      "outputs": [],
      "source": [
        "path_figures = F\"/content/drive/My Drive/Denoising/figures/\"\n",
        "\n",
        "device = 'cpu'\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int).cpu()\n",
        "#N_theory = torch.arange(500,6010,55).to(torch.int)\n",
        "\n",
        "Cinverse = (N/M).cpu().numpy()\n",
        "#Cinverse_theory = (N_theory/M).cpu().numpy()\n",
        "Err_emp_cifar_fullR = torch.load(path2+\"cifar-emp-fullR.pt\",map_location = device).numpy()\n",
        "Err_cifar_fullR = torch.load(path1+\"cifar-fullR.pt\",map_location = device).numpy()\n",
        "\n",
        "plt.plot(Cinverse,Err_cifar_fullR[0,:],color=\"green\")\n",
        "plt.plot(Cinverse,Err_emp_cifar_fullR[0,:],'.',markersize = 15,color=\"green\")\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"1/c = N/d\")\n",
        "plt.ylabel(\"Generalization Error\")\n",
        "plt.legend(['Theoretical Result','Empirical Result'],fontsize=13.5)\n",
        "#plt.title('CIFAR Dataset')\n",
        "plt.savefig(path_figures+\"cifar-error-fullR.pdf\", bbox_inches='tight', facecolor='white', dpi = 300, format = 'pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0IVRCW3DcWd"
      },
      "outputs": [],
      "source": [
        "path_figures = F\"/content/drive/My Drive/Denoising/figures/\"\n",
        "\n",
        "device = 'cpu'\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int).cpu()\n",
        "#N_theory = torch.arange(500,6010,55).to(torch.int)\n",
        "\n",
        "Cinverse = (N/M).cpu().numpy()\n",
        "#Cinverse_theory = (N_theory/M).cpu().numpy()\n",
        "Err_emp_stl10_fullR = torch.load(path2+\"stl10-emp-fullR.pt\",map_location = device).numpy()\n",
        "Err_stl10_fullR = torch.load(path1+\"stl10-fullR.pt\",map_location = device).numpy()\n",
        "\n",
        "plt.plot(Cinverse,Err_stl10_fullR[0,:],color=\"blue\")\n",
        "plt.plot(Cinverse,Err_emp_stl10_fullR[0,:],'.',markersize = 15,color=\"blue\")\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"1/c = N/d\")\n",
        "plt.ylabel(\"Generalization Error\")\n",
        "plt.legend(['Theoretical Result','Empirical Result'],fontsize=13.5)\n",
        "#plt.title('CIFAR Dataset')\n",
        "plt.savefig(path_figures+\"stl10-error-fullR.pdf\", bbox_inches='tight', facecolor='white', dpi = 300, format = 'pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luFcpH_KDuc5"
      },
      "outputs": [],
      "source": [
        "path_figures = F\"/content/drive/My Drive/Denoising/figures/\"\n",
        "\n",
        "device = 'cpu'\n",
        "M = 3072\n",
        "N = torch.arange(1050,10500,550).to(torch.int).cpu()\n",
        "#N_theory = torch.arange(500,6010,55).to(torch.int)\n",
        "\n",
        "Cinverse = (N/M).cpu().numpy()\n",
        "#Cinverse_theory = (N_theory/M).cpu().numpy()\n",
        "Err_emp_svhn_fullR = torch.load(path2+\"svhn-emp-fullR.pt\",map_location = device).numpy()\n",
        "Err_svhn_fullR = torch.load(path1+\"svhn-fullR.pt\",map_location = device).numpy()\n",
        "\n",
        "plt.plot(Cinverse,Err_svhn_fullR[0,:],color=\"red\")\n",
        "plt.plot(Cinverse,Err_emp_svhn_fullR[0,:],'.',markersize = 15,color=\"red\")\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"1/c = N/d\")\n",
        "plt.ylabel(\"Generalization Error\")\n",
        "plt.legend(['Theoretical Result','Empirical Result'],fontsize=13.5)\n",
        "#plt.title('CIFAR Dataset')\n",
        "plt.savefig(path_figures+\"svhn-error-fullR.pdf\", bbox_inches='tight', facecolor='white', dpi = 300, format = 'pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEKmcztvq-kT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}